{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-Sparse Logistic Regression applied to the real proteomics data from the TCGA/CPTAC Breast Cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from matplotlib_venn import venn3, venn3_circles, venn2\n",
    "\n",
    "repo_path = '/Users/alex/Documents/gslr/'\n",
    "interactome_path = repo_path + 'experiments/algorithms/pcsf/inbiomap_temp.tsv'\n",
    "\n",
    "sys.path.append(repo_path + 'gslr/')\n",
    "import gslr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medullo = pd.read_csv('/Users/alex/Documents/proteomics/data_preparation/proteomics_data/medullo_inbiomap_exp.tsv', index_col=0)\n",
    "# ovarian = pd.read_csv('/Users/alex/Documents/proteomics/data_preparation/proteomics_data/ovarian_inbiomap_exp.tsv', index_col=0)\n",
    "brca = pd.read_csv('/Users/alex/Documents/proteomics/data_preparation/proteomics_data/brca_inbiomap_exp.tsv', index_col=0)\n",
    "\n",
    "# medullo_labels = pd.read_csv('/Users/alex/Documents/proteomics/data_preparation/proteomics_data/raw/medullo_labels.csv', index_col=0)\n",
    "# ovarian_labels = pd.read_csv('/Users/alex/Documents/proteomics/data_preparation/proteomics_data/raw/ovarian_labels.csv', index_col=0)\n",
    "brca_labels = pd.read_csv('/Users/alex/Documents/proteomics/data_preparation/proteomics_data/raw/brca_labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Load Interactome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>protein2</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZNF91</td>\n",
       "      <td>NDEL1</td>\n",
       "      <td>1.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZNF91</td>\n",
       "      <td>ELAVL1</td>\n",
       "      <td>1.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZNF91</td>\n",
       "      <td>SUMO1</td>\n",
       "      <td>1.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZNF91</td>\n",
       "      <td>SUMO3</td>\n",
       "      <td>1.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZNF91</td>\n",
       "      <td>CHMP5</td>\n",
       "      <td>1.241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein1 protein2   cost\n",
       "0    ZNF91    NDEL1  1.253\n",
       "1    ZNF91   ELAVL1  1.254\n",
       "2    ZNF91    SUMO1  1.245\n",
       "3    ZNF91    SUMO3  1.245\n",
       "4    ZNF91    CHMP5  1.241"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbiomap_experimentally = pd.read_csv(interactome_path, sep='\\t', names=['protein1','protein2','cost'])\n",
    "inbiomap_experimentally.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  1228],\n",
       "       [    0,  1279],\n",
       "       [    0,  4071],\n",
       "       ..., \n",
       "       [14190, 14237],\n",
       "       [14191, 14378],\n",
       "       [14192, 14539]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edges, nodes) = pd.factorize(inbiomap_experimentally[[\"protein1\",\"protein2\"]].unstack())\n",
    "edges = edges.reshape(inbiomap_experimentally[[\"protein1\",\"protein2\"]].shape, order='F')\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((111, 16349), (111,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = brca.copy()\n",
    "labels = brca_labels.loc['PAM50 mRNA']\n",
    "dataset.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZNF91</th>\n",
       "      <th>ACP5</th>\n",
       "      <th>SLC27A2</th>\n",
       "      <th>PAX9</th>\n",
       "      <th>ADAM15</th>\n",
       "      <th>ELOVL2</th>\n",
       "      <th>DDX60L</th>\n",
       "      <th>FGF7</th>\n",
       "      <th>CDHR5</th>\n",
       "      <th>LYPD3</th>\n",
       "      <th>...</th>\n",
       "      <th>CNR2</th>\n",
       "      <th>GIG44</th>\n",
       "      <th>LINC00588</th>\n",
       "      <th>TAAR2</th>\n",
       "      <th>CHRNE</th>\n",
       "      <th>ANKAR</th>\n",
       "      <th>DHH</th>\n",
       "      <th>CYSLTR1</th>\n",
       "      <th>COL23A1</th>\n",
       "      <th>MEDAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AO-A12D.01TCGA</th>\n",
       "      <td>-1.102122</td>\n",
       "      <td>-0.747811</td>\n",
       "      <td>-3.292756</td>\n",
       "      <td>1.976195</td>\n",
       "      <td>2.341935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.513581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8-A131.01TCGA</th>\n",
       "      <td>-0.644553</td>\n",
       "      <td>1.496776</td>\n",
       "      <td>-2.061312</td>\n",
       "      <td>2.496602</td>\n",
       "      <td>1.589877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.531213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.660745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO-A12B.01TCGA</th>\n",
       "      <td>1.274661</td>\n",
       "      <td>1.055714</td>\n",
       "      <td>0.634450</td>\n",
       "      <td>-1.333296</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.604399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2-A10A.02TCGA</th>\n",
       "      <td>-9.048165</td>\n",
       "      <td>1.054283</td>\n",
       "      <td>0.867457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.458240</td>\n",
       "      <td>0.180121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.390064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BH-A18Q.02TCGA</th>\n",
       "      <td>-3.728792</td>\n",
       "      <td>1.302662</td>\n",
       "      <td>-2.554563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.470390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.979158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.524724</td>\n",
       "      <td>-0.998961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.310081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ZNF91      ACP5   SLC27A2      PAX9    ADAM15  ELOVL2  \\\n",
       "AO-A12D.01TCGA -1.102122 -0.747811 -3.292756  1.976195  2.341935     0.0   \n",
       "C8-A131.01TCGA -0.644553  1.496776 -2.061312  2.496602  1.589877     0.0   \n",
       "AO-A12B.01TCGA  1.274661  1.055714  0.634450 -1.333296 -0.335566     0.0   \n",
       "E2-A10A.02TCGA -9.048165  1.054283  0.867457  0.000000 -0.089739     0.0   \n",
       "BH-A18Q.02TCGA -3.728792  1.302662 -2.554563  0.000000 -0.470390     0.0   \n",
       "\n",
       "                  DDX60L  FGF7  CDHR5     LYPD3  ...    CNR2  GIG44  \\\n",
       "AO-A12D.01TCGA  0.086535   0.0    0.0  0.280834  ...     0.0    0.0   \n",
       "C8-A131.01TCGA -0.531213   0.0    0.0 -0.660745  ...     0.0    0.0   \n",
       "AO-A12B.01TCGA  1.116687   0.0    0.0 -0.044561  ...     0.0    0.0   \n",
       "E2-A10A.02TCGA  0.975862   0.0    0.0 -0.315775  ...     0.0    0.0   \n",
       "BH-A18Q.02TCGA  0.332501   0.0    0.0 -1.979158  ...     0.0    0.0   \n",
       "\n",
       "                LINC00588  TAAR2     CHRNE     ANKAR  DHH  CYSLTR1   COL23A1  \\\n",
       "AO-A12D.01TCGA        0.0    0.0 -1.513581  0.000000  0.0      0.0  0.000000   \n",
       "C8-A131.01TCGA        0.0    0.0  0.112400  0.000000  0.0      0.0  0.000000   \n",
       "AO-A12B.01TCGA        0.0    0.0 -0.604399  0.000000  0.0      0.0  0.000000   \n",
       "E2-A10A.02TCGA        0.0    0.0 -4.458240  0.180121  0.0      0.0 -5.390064   \n",
       "BH-A18Q.02TCGA        0.0    0.0 -3.524724 -0.998961  0.0      0.0 -1.310081   \n",
       "\n",
       "                MEDAG  \n",
       "AO-A12D.01TCGA    0.0  \n",
       "C8-A131.01TCGA    0.0  \n",
       "AO-A12B.01TCGA    0.0  \n",
       "E2-A10A.02TCGA    0.0  \n",
       "BH-A18Q.02TCGA    0.0  \n",
       "\n",
       "[5 rows x 16349 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.transpose().reindex(index=nodes).transpose()\n",
    "X = dataset.values\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 3, 0, 1, 1, 2, 3, 3, 1, 2, 1, 2, 0, 0, 2, 1, 3, 1, 0, 3, 2,\n",
       "       1, 3, 0, 2, 1, 2, 0, 2, 3, 0, 0, 3, 2, 0, 3, 2, 3, 2, 1, 3, 1, 2, 1,\n",
       "       2, 3, 2, 3, 1, 2, 3, 0, 0, 2, 3, 3, 1, 2, 1, 0, 3, 3, 0, 2, 2, 1, 3,\n",
       "       0, 3, 2, 2, 3, 1, 2, 3, 1, 3, 0, 2, 2, 3, 0, 2, 0, 3, 3, 0, 3, 0, 3,\n",
       "       2, 1, 0, 0, 2, 3, 2, 3, 0, 3, 3, 0, 2, 0, 3, 0, 4, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeler = LabelEncoder()\n",
    "labeler.fit(labels)\n",
    "y = labeler.transform(labels)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Graph-Sparse Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = len(nodes)\n",
    "c = 5\n",
    "\n",
    "graph_opts = gslr.GraphOptions(edges=edges, root=-1, num_clusters=1, pruning='strong')\n",
    "\n",
    "sparsity_low = 150\n",
    "sparsity_high = 350\n",
    "\n",
    "verbosity_level = 1\n",
    "\n",
    "num_steps = 25\n",
    "possible_steps = np.array([0.03, 0.1, 0.3])\n",
    "steps = np.tile(possible_steps, (num_steps, 1))\n",
    "\n",
    "W0 = np.zeros((c, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 2:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 3:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 4:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 5:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 6:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 7:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 8:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 9:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 10:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 11:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 12:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 13:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 14:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 15:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 16:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 17:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 18:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 19:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 20:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 21:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 22:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 23:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 24:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "iteration 25:\n",
      "  loss_cur = 1.6094379124340985   loss_next = 1.8155318506232232   step_size = 0.03\n",
      "  loss_cur = 1.6094379124340985   loss_next = 5.289145745312761   step_size = 0.1\n",
      "  loss_cur = 1.6094379124340985   loss_next = 16.934794370801768   step_size = 0.3\n",
      "  best_step_size: 0.0\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n",
      "WARNING: returning sparsity 1 although minimum sparsity 150 was requested.\n"
     ]
    }
   ],
   "source": [
    "W_hat, losses = gslr.gslr(X, y, W0, sparsity_low, sparsity_high, graph_opts, steps, verbosity_level, edge_costs=inbiomap_experimentally.cost.values, edge_costs_multiplier=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.23423423423423423\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAACXBJREFUeJzt3V+Ipfddx/HP18TeRB2qKaVuottK\nKay9sLL0qkhvlERY4x8o3asqwVUwYO+s3rS9EERUvKmVkYZWqC2hVs1CoHqh1IsimS3F5g/VUFKa\nGJOtgantTWj79WJOcVgyk8nOOfvkfOf1upmZZ8/MfH887Huf/c2Z81R3B4C5fmDpAQDYLKEHGE7o\nAYYTeoDhhB5gOKEHGE7oAYYTeoDhhB5guNuXHiBJ7rzzzj5//vzSYwBslWvXrn2ju9/wSo97TYT+\n/Pnz2dvbW3oMgK1SVV87yeNs3QAMJ/QAwwk9wHBCDzDc2kNfVW+pqo9V1WfW/bUBePVOFPqqerCq\nXqiqx244fk9VfaWqnqqqDyRJd3+1u+/fxLAAvHonvaL/eJJ7Dh+oqtuSfCTJvUkuJLlcVRfWOh0A\np3ai0Hf355O8eMPhdyZ5anUF/1KSTye5b83zAXBKp9mjP5fk64c+fibJuar6sar6yyTvqKrfP+qT\nq+pKVe1V1d7169dPMQYAx1n7b8Z29/8k+e0TPG43yW6SXLx40R3KATbkNFf0zya5+9DHd62OAfAa\ncprQP5rkrVX15qp6XZL3Jnl4PWMBsC4nfXrlp5J8IcnbquqZqrq/u7+T5IEkn0vyZJKHuvvxzY0K\nwM040R59d18+4vgjSR5Z60QArJWXQAAYTugBhhN6gOEWDX1VXaqq3f39/SXHABht0dB399XuvrKz\ns7PkGACj2boBGE7oAYYTeoDhhB5gOKEHGE7oAYYTeoDhhB5gOL8ZCzCc34wFGM7WDcBwQg8wnNAD\nDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNe6ARjOa90ADGfrBmA4oQcYTugBhhN6gOGEHmA4\noQcYTugBhhN6gOGEHmA4oQcYTugBhvOiZgDDeVEzgOFs3QAMJ/QAwwk9wHBCDzCc0AMMJ/QAwwk9\nwHBCDzCc0AMMJ/QAwwk9wHBCDzCc0AMMJ/QAw3k9eoDhvB49wHC2bgCGE3qA4YQeYDihBxhO6AGG\nE3qA4YQeYDihBxhO6AGGE3qA4YQeYDihBxhO6AGGE3qA4YQeYDihBxhO6AGGcytBgOHcShBgOFs3\nAMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNAD\nDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8w3KKhr6pLVbW7v7+/5BgAoy0a+u6+2t1XdnZ2lhwD\nYDRbNwDDCT3AcEIPMJzQAwwn9ADDCT3AcEIPMJzQAwwn9ADDCT3AcEIPMJzQAwwn9ADDCT3AcEIP\nMJzQAwwn9ADDCT3AcEIPMJzQAwwn9ADDCT3AcEIPMJzQAwwn9ADDCT3AcEIPMJzQAwwn9ADDCT3A\ncEIPMJzQAwy3aOir6lJV7e7v7y85BsBoi4a+u69295WdnZ0lxwAYzdYNwHBCDzCc0AMMJ/QAwwk9\nwHBCDzCc0AMMJ/QAwwk9wHBCDzCc0AMMJ/QAwwk9wHBCDzCc0AMMJ/QAw92+9ACn8eGrj+eJ//rm\n0mMA3LQLP/4j+eCln97o93BFDzDcVl/Rb/pfQYAJXNEDDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBw\nQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJ\nPcBwQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwQg8wnNADDCf0AMMJPcBwt6/7C1bVHUn+\nIslLSf6luz+57u8BwMmd6Iq+qh6sqheq6rEbjt9TVV+pqqeq6gOrw7+a5DPd/ZtJfmnN8wLwKp10\n6+bjSe45fKCqbkvykST3JrmQ5HJVXUhyV5Kvrx723fWMCcDNOlHou/vzSV684fA7kzzV3V/t7peS\nfDrJfUmeyUHsT/z1Adic04T4XP7/yj05CPy5JJ9N8mtV9dEkV4/65Kq6UlV7VbV3/fr1U4wBwHHW\n/sPY7v52kt84weN2k+wmycWLF3vdcwBw4DRX9M8mufvQx3etjgHwGnKa0D+a5K1V9eaqel2S9yZ5\neD1jAbAuJ3165aeSfCHJ26rqmaq6v7u/k+SBJJ9L8mSSh7r78c2NCsDNONEefXdfPuL4I0keWetE\nAKyVpz8CDCf0AMMJPcBwi4a+qi5V1e7+/v6SYwCMVt3L/65SVV1P8rWb/PQ7k3xjjeNsA2s+G6z5\nbDjNmn+yu9/wSg96TYT+NKpqr7svLj3HrWTNZ4M1nw23Ys326AGGE3qA4SaEfnfpARZgzWeDNZ8N\nG1/z1u/RA3C8CVf0ABxjq0N/xD1rR6uqp6vqy1X1paraW3qeTXi5exRX1Y9W1T9V1X+u3r5+yRnX\n7Yg1f6iqnl2d6y9V1S8uOeM6VdXdVfXPVfVEVT1eVb+7Oj72PB+z5o2f563dulnds/Y/kvx8Du5u\n9WiSy939xKKDbVhVPZ3kYnePfa5xVf1ckm8l+evufvvq2B8nebG7/2j1j/rru/v3lpxznY5Y84eS\nfKu7/2TJ2Tahqt6U5E3d/cWq+uEk15L8cpJfz9DzfMya35MNn+dtvqI/6p61bLkj7lF8X5JPrN7/\nRA7+goxxxJrH6u7nuvuLq/f/NwcvdX4ug8/zMWveuG0O/VH3rJ2uk/xjVV2rqitLD3MLvbG7n1u9\n/99J3rjkMLfQA1X176utnTHbGIdV1fkk70jybzkj5/mGNScbPs/bHPqz6l3d/bNJ7k3yO6v/8p8p\nfbDfuJ17jq/OR5P8VJKfSfJckj9ddpz1q6ofSvK3Sd7f3d88/GdTz/PLrHnj53mbQ38m71nb3c+u\n3r6Q5O9ysIV1Fjy/2uP8/l7nCwvPs3Hd/Xx3f7e7v5fkrzLsXFfVD+YgeJ/s7s+uDo8+zy+35ltx\nnrc59GfunrVVdcfqhzipqjuS/EKSx47/rDEeTvK+1fvvS/IPC85yS3w/eCu/kkHnuqoqyceSPNnd\nf3boj8ae56PWfCvO89Y+6yZJVk9D+vMktyV5sLv/cOGRNqqq3pKDq/jk4DaQfzNxzat7FL87B6/q\n93ySDyb5+yQPJfmJHLzS6Xu6e8wPL49Y87tz8N/5TvJ0kt86tH+91arqXUn+NcmXk3xvdfgPcrBn\nPfI8H7Pmy9nwed7q0APwyrZ56waAExB6gOGEHmA4oQcYTugBhhN6gOGEHmA4oQcY7v8AdlR3ZGvo\n5lAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1090ca550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = gslr.predict(X, W_hat)\n",
    "num_cor = gslr.num_correct(y, yhat)\n",
    "print('Train accuracy: {}'.format(num_cor / float(len(y))))\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Unpack Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1139d3dd8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+wAAAHVCAYAAABrM3HEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGMpNxkZFoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113d02e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefs = pd.DataFrame(W_hat, columns=dataset.columns)\n",
    "coefs.transpose().plot(figsize=(17,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = coefs.columns[(coefs != 0).any()].tolist()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.to_pickle('brca_coefs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
